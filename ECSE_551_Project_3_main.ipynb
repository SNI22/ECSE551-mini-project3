{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jA04fuOR3Dy"
   },
   "source": [
    "# ECSE 551 MP3 G17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0PtEpsotR6FH"
   },
   "source": [
    "## Define constants, import libraries, setup device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T22:42:51.961608Z",
     "start_time": "2024-11-26T22:42:50.212684Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yn24H1_YQsbg",
    "outputId": "76d07322-8096-4f1d-e77c-1d6de29ba5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Connect to Google Drive to load the dataset\n",
    "# Make sure to run this cell first!\n",
    "# from google.colab import drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# drive.mount('/content/drive')\n",
    "# Define Global Constants\n",
    "# Please modify the path according to the actual situation\n",
    "TRAIN_PKL_FILE = '/home/shiyao/ECSE551-mini-project3/Train.pkl'\n",
    "TRAIN_LABEL_FILE = '/home/shiyao/ECSE551-mini-project3/Train_labels.csv'\n",
    "TEST_PKL_FILE = '/home/shiyao/ECSE551-mini-project3/Test.pkl'\n",
    "SUBMISSION_FILE = '/home/shiyao/ECSE551-mini-project3/Submission.csv'\n",
    "\n",
    "# Set up the device\n",
    "# For Google Colab, switch the GPU runtime to gain best performance\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdk157xdTF-z"
   },
   "source": [
    "## Scripts Starts Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYNPfIdAUr7V"
   },
   "source": [
    "### Load and Read the PKL Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "638MRjaPTEPb",
    "outputId": "dd84d426-ee05-4a51-a7ed-92a44138e390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Data dimensions: (60000, 1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File paths\n",
    "pkl_file_path = TRAIN_PKL_FILE\n",
    "csv_file_path = TRAIN_LABEL_FILE\n",
    "\n",
    "# Open and load the pkl file\n",
    "with open(pkl_file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "\n",
    "# Load the CSV file\n",
    "labels_df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Create a dictionary to map IDs to classes\n",
    "labels_dict = dict(zip(labels_df['id'], labels_df['class']))\n",
    "\n",
    "# Check data structure\n",
    "print(type(data))  # View data type\n",
    "\n",
    "# If the data is an image array\n",
    "if isinstance(data, np.ndarray):\n",
    "    print(\"Data dimensions:\", data.shape)  # Check data dimensions\n",
    "\n",
    "    # Assign labels from the CSV file\n",
    "    image_labels = [labels_dict.get(i+1, 'Unknown') for i in range(len(data))]\n",
    "\n",
    "    # Display the first image (assuming it is a grayscale image)\n",
    "    plt.imshow(data[0].squeeze(), cmap='gray')\n",
    "    plt.title(f\"Label: {image_labels[0]}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K31TXLdfqlC8"
   },
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9kLuNm0qlC8"
   },
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "eXsTA_3RqlC8"
   },
   "outputs": [],
   "source": [
    "# 加载训练数据和标签\n",
    "with open(TRAIN_PKL_FILE, 'rb') as file:\n",
    "    train_data = pickle.load(file)\n",
    "\n",
    "labels_df = pd.read_csv(TRAIN_LABEL_FILE)\n",
    "labels_dict = dict(zip(labels_df['id'], labels_df['class']))\n",
    "train_labels = [labels_dict.get(i + 1, 'Unknown') for i in range(len(train_data))]\n",
    "\n",
    "# 定义自定义数据集\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "dataset = CustomDataset(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFqcAifXqlC9"
   },
   "source": [
    "### Define the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DAfCRkuqqlC9"
   },
   "outputs": [],
   "source": [
    "# 定义 CNN 模型\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, fc_units=128):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(fc_units, 10)  # 假设有 10 个类别\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # 移除了多余的 unsqueeze\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlF90te5qlC9"
   },
   "source": [
    "### X-Validation Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dRqWMboLqlC9",
    "outputId": "4950ee88-b808-43f9-f37a-1eb44ef5a643"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1, Validation Accuracy: 79.22%\n",
      "Epoch 2, Validation Accuracy: 84.55%\n",
      "Epoch 3, Validation Accuracy: 85.46%\n",
      "Epoch 4, Validation Accuracy: 88.17%\n",
      "Epoch 5, Validation Accuracy: 89.38%\n",
      "Epoch 6, Validation Accuracy: 89.52%\n",
      "Epoch 7, Validation Accuracy: 89.32%\n",
      "Epoch 8, Validation Accuracy: 90.80%\n",
      "Epoch 9, Validation Accuracy: 90.25%\n",
      "Epoch 10, Validation Accuracy: 91.03%\n",
      "Fold 2\n",
      "Epoch 1, Validation Accuracy: 80.72%\n",
      "Epoch 2, Validation Accuracy: 84.09%\n",
      "Epoch 3, Validation Accuracy: 87.43%\n",
      "Epoch 4, Validation Accuracy: 88.32%\n",
      "Epoch 5, Validation Accuracy: 88.78%\n",
      "Epoch 6, Validation Accuracy: 90.20%\n",
      "Epoch 7, Validation Accuracy: 90.06%\n",
      "Epoch 8, Validation Accuracy: 90.18%\n",
      "Epoch 9, Validation Accuracy: 90.39%\n",
      "Epoch 10, Validation Accuracy: 90.88%\n",
      "Fold 3\n",
      "Epoch 1, Validation Accuracy: 84.74%\n",
      "Epoch 2, Validation Accuracy: 88.77%\n",
      "Epoch 3, Validation Accuracy: 89.42%\n",
      "Epoch 4, Validation Accuracy: 90.36%\n",
      "Epoch 5, Validation Accuracy: 91.57%\n",
      "Epoch 6, Validation Accuracy: 90.99%\n",
      "Epoch 7, Validation Accuracy: 92.45%\n",
      "Epoch 8, Validation Accuracy: 92.40%\n",
      "Epoch 9, Validation Accuracy: 92.44%\n",
      "Epoch 10, Validation Accuracy: 92.36%\n",
      "Fold 4\n",
      "Epoch 1, Validation Accuracy: 83.83%\n",
      "Epoch 2, Validation Accuracy: 87.88%\n",
      "Epoch 3, Validation Accuracy: 90.03%\n",
      "Epoch 4, Validation Accuracy: 90.35%\n",
      "Epoch 5, Validation Accuracy: 91.42%\n",
      "Epoch 6, Validation Accuracy: 91.53%\n",
      "Epoch 7, Validation Accuracy: 91.99%\n",
      "Epoch 8, Validation Accuracy: 92.17%\n",
      "Epoch 9, Validation Accuracy: 92.46%\n",
      "Epoch 10, Validation Accuracy: 92.35%\n",
      "Fold 5\n",
      "Epoch 1, Validation Accuracy: 85.27%\n",
      "Epoch 2, Validation Accuracy: 88.74%\n",
      "Epoch 3, Validation Accuracy: 90.60%\n",
      "Epoch 4, Validation Accuracy: 91.55%\n",
      "Epoch 5, Validation Accuracy: 91.40%\n",
      "Epoch 6, Validation Accuracy: 91.53%\n",
      "Epoch 7, Validation Accuracy: 92.14%\n",
      "Epoch 8, Validation Accuracy: 92.07%\n",
      "Epoch 9, Validation Accuracy: 91.70%\n",
      "Epoch 10, Validation Accuracy: 92.82%\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    train_subset = torch.utils.data.Subset(dataset, train_idx)\n",
    "    val_subset = torch.utils.data.Subset(dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = SimpleCNN().to(DEVICE)  # 将模型移动到设备上\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # 训练模型\n",
    "    for epoch in range(10):  # 根据需要调整 epoch 数量\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(DEVICE)  # 移动数据到设备上\n",
    "            labels = labels.to(DEVICE)  # 移动标签到设备上\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # 在验证集上评估模型\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(DEVICE)  # 移动数据到设备上\n",
    "                labels = labels.to(DEVICE)  # 移动标签到设备上\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:26:36,150] A new study created in memory with name: no-name-f6ef63b7-532a-466b-8471-6ac14e930750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1612144/3453002419.py:27: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:28:10,206] Trial 0 finished with value: 81.36333333333334 and parameters: {'lr': 0.0001569301091955081, 'fc_units': 64, 'batch_size': 64}. Best is trial 0 with value: 81.36333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:29:02,362] Trial 1 finished with value: 32.57 and parameters: {'lr': 0.005910029431733149, 'fc_units': 64, 'batch_size': 128}. Best is trial 0 with value: 81.36333333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:29:54,122] Trial 2 finished with value: 81.63166666666666 and parameters: {'lr': 0.0024982923262261256, 'fc_units': 64, 'batch_size': 128}. Best is trial 2 with value: 81.63166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:32:39,320] Trial 3 finished with value: 46.35 and parameters: {'lr': 1.1186074075319805e-05, 'fc_units': 128, 'batch_size': 32}. Best is trial 2 with value: 81.63166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:35:19,141] Trial 4 finished with value: 65.14333333333333 and parameters: {'lr': 0.004253368240595595, 'fc_units': 128, 'batch_size': 32}. Best is trial 2 with value: 81.63166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:36:11,597] Trial 5 finished with value: 89.87 and parameters: {'lr': 0.0011079848663358741, 'fc_units': 256, 'batch_size': 128}. Best is trial 5 with value: 89.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:37:38,267] Trial 6 finished with value: 77.15833333333333 and parameters: {'lr': 7.897669491758342e-05, 'fc_units': 128, 'batch_size': 64}. Best is trial 5 with value: 89.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:39:01,740] Trial 7 finished with value: 88.72 and parameters: {'lr': 0.0003493241765867984, 'fc_units': 256, 'batch_size': 64}. Best is trial 5 with value: 89.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:40:32,330] Trial 8 finished with value: 73.37666666666667 and parameters: {'lr': 4.5090078489791086e-05, 'fc_units': 256, 'batch_size': 64}. Best is trial 5 with value: 89.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:43:16,524] Trial 9 finished with value: 90.96166666666666 and parameters: {'lr': 0.0012935482209570999, 'fc_units': 256, 'batch_size': 32}. Best is trial 9 with value: 90.96166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:46:00,623] Trial 10 finished with value: 91.69833333333334 and parameters: {'lr': 0.0006563768858677396, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:48:39,113] Trial 11 finished with value: 91.455 and parameters: {'lr': 0.0007363814746900642, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:51:23,714] Trial 12 finished with value: 91.03666666666666 and parameters: {'lr': 0.00044420423886887354, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:54:02,914] Trial 13 finished with value: 91.38499999999999 and parameters: {'lr': 0.0008426040687764063, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:56:46,195] Trial 14 finished with value: 87.52 and parameters: {'lr': 0.00017526783716974285, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 19:59:30,885] Trial 15 finished with value: 84.08 and parameters: {'lr': 0.0020018346731587922, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:02:12,140] Trial 16 finished with value: 11.021666666666667 and parameters: {'lr': 0.009514219724868047, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:04:54,996] Trial 17 finished with value: 91.22833333333332 and parameters: {'lr': 0.0005092312417343149, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:07:36,954] Trial 18 finished with value: 84.71000000000001 and parameters: {'lr': 0.00018219586674633197, 'fc_units': 64, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:08:31,454] Trial 19 finished with value: 56.585 and parameters: {'lr': 3.5435019132185476e-05, 'fc_units': 128, 'batch_size': 128}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:11:11,668] Trial 20 finished with value: 91.69000000000001 and parameters: {'lr': 0.0007512338964845925, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:13:51,456] Trial 21 finished with value: 91.58 and parameters: {'lr': 0.0006723965707852482, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:16:34,080] Trial 22 finished with value: 89.06333333333333 and parameters: {'lr': 0.0022404556743864496, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:19:17,238] Trial 23 finished with value: 88.53999999999999 and parameters: {'lr': 0.000243311203682933, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:22:00,188] Trial 24 finished with value: 91.65 and parameters: {'lr': 0.000552623173350062, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:24:38,674] Trial 25 finished with value: 84.63666666666667 and parameters: {'lr': 9.144399902363797e-05, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:27:22,025] Trial 26 finished with value: 90.15666666666667 and parameters: {'lr': 0.0013690137221782468, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:30:03,547] Trial 27 finished with value: 89.53 and parameters: {'lr': 0.00032552819874625513, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:31:31,991] Trial 28 finished with value: 84.79 and parameters: {'lr': 0.0030580232539433173, 'fc_units': 64, 'batch_size': 64}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:32:25,190] Trial 29 finished with value: 86.88833333333335 and parameters: {'lr': 0.0005471068806240213, 'fc_units': 128, 'batch_size': 128}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:33:52,662] Trial 30 finished with value: 83.90166666666667 and parameters: {'lr': 0.00024721429712033793, 'fc_units': 64, 'batch_size': 64}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:36:34,865] Trial 31 finished with value: 91.62999999999998 and parameters: {'lr': 0.000806816115602819, 'fc_units': 256, 'batch_size': 32}. Best is trial 10 with value: 91.69833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:39:18,782] Trial 32 finished with value: 92.33166666666666 and parameters: {'lr': 0.0009611873663184803, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:42:05,402] Trial 33 finished with value: 90.09333333333333 and parameters: {'lr': 0.0015963562945062665, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:44:43,967] Trial 34 finished with value: 91.68833333333332 and parameters: {'lr': 0.0010380795410160858, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:45:39,762] Trial 35 finished with value: 70.66333333333333 and parameters: {'lr': 0.003911153843686536, 'fc_units': 64, 'batch_size': 128}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:48:24,165] Trial 36 finished with value: 91.64500000000001 and parameters: {'lr': 0.0008832836419005828, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:51:04,926] Trial 37 finished with value: 89.405 and parameters: {'lr': 0.0016972121850828946, 'fc_units': 128, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:51:56,485] Trial 38 finished with value: 37.78333333333333 and parameters: {'lr': 0.005538587035896976, 'fc_units': 256, 'batch_size': 128}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:54:36,293] Trial 39 finished with value: 91.35166666666666 and parameters: {'lr': 0.0011064872526919767, 'fc_units': 64, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:56:06,313] Trial 40 finished with value: 82.46333333333334 and parameters: {'lr': 0.00011545488026019737, 'fc_units': 256, 'batch_size': 64}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:58:48,062] Trial 41 finished with value: 90.42666666666666 and parameters: {'lr': 0.00046126917330592727, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:01:28,815] Trial 42 finished with value: 91.115 and parameters: {'lr': 0.0011252670536905703, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:04:12,509] Trial 43 finished with value: 89.82666666666668 and parameters: {'lr': 0.00034303774644561574, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:06:57,415] Trial 44 finished with value: 91.68666666666668 and parameters: {'lr': 0.0005891333007468906, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:09:41,609] Trial 45 finished with value: 79.38833333333334 and parameters: {'lr': 0.0026707602110099264, 'fc_units': 128, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:12:23,304] Trial 46 finished with value: 91.77666666666667 and parameters: {'lr': 0.0009499612972525634, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:15:05,251] Trial 47 finished with value: 91.585 and parameters: {'lr': 0.0010354740468471273, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:16:33,178] Trial 48 finished with value: 90.30499999999999 and parameters: {'lr': 0.0016360966224671968, 'fc_units': 256, 'batch_size': 64}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 21:19:12,990] Trial 49 finished with value: 53.223333333333336 and parameters: {'lr': 1.1301402257604775e-05, 'fc_units': 256, 'batch_size': 32}. Best is trial 32 with value: 92.33166666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 92.33166666666666\n",
      "  Params: \n",
      "    lr: 0.0009611873663184803\n",
      "    fc_units: 256\n",
      "    batch_size: 32\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torch.nn.parallel import DataParallel\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, fc_units=128):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, fc_units)\n",
    "        self.fc2 = nn.Linear(fc_units, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "    fc_units = trial.suggest_categorical('fc_units', [64, 128, 256])\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    # Use all available GPUs\n",
    "    device_count = torch.cuda.device_count()\n",
    "    print(f\"Using {device_count} GPUs\")\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size*device_count, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size*device_count, shuffle=False)\n",
    "\n",
    "        # Initialize model and wrap with DataParallel\n",
    "        model = SimpleCNN(fc_units=fc_units)\n",
    "        model = DataParallel(model).to('cuda')\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        for epoch in range(10):\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                images = images.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to('cuda')\n",
    "                labels = labels.to('cuda')\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "    \n",
    "    return sum(val_accuracies) / len(val_accuracies)\n",
    "\n",
    "# Create and optimize study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 02:11:30,341] A new study created in memory with name: no-name-d26aa85b-7ec6-4f74-8db5-745a545de551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 02:30:05,964] Trial 0 finished with value: 94.16833333333334 and parameters: {'conv1_out': 256, 'conv2_out': 256, 'conv3_out': 1024, 'fc1_units': 1024, 'fc2_units': 512, 'dropout_rate': 0.4142074775259702, 'lr': 4.018406442295461e-05, 'batch_size': 64}. Best is trial 0 with value: 94.16833333333334.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 02:46:17,932] Trial 1 finished with value: 96.01833333333333 and parameters: {'conv1_out': 64, 'conv2_out': 128, 'conv3_out': 512, 'fc1_units': 2048, 'fc2_units': 1024, 'dropout_rate': 0.408431524015743, 'lr': 0.0010642716113742903, 'batch_size': 64}. Best is trial 1 with value: 96.01833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 03:01:35,443] Trial 2 finished with value: 94.19000000000001 and parameters: {'conv1_out': 128, 'conv2_out': 128, 'conv3_out': 512, 'fc1_units': 1024, 'fc2_units': 512, 'dropout_rate': 0.39026142170332334, 'lr': 0.00013915775022853332, 'batch_size': 64}. Best is trial 1 with value: 96.01833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 03:17:05,752] Trial 3 finished with value: 96.38499999999999 and parameters: {'conv1_out': 64, 'conv2_out': 256, 'conv3_out': 512, 'fc1_units': 1024, 'fc2_units': 512, 'dropout_rate': 0.21693061981019512, 'lr': 0.0020270387448699644, 'batch_size': 64}. Best is trial 3 with value: 96.38499999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 03:44:25,656] Trial 4 finished with value: 96.36166666666668 and parameters: {'conv1_out': 128, 'conv2_out': 128, 'conv3_out': 256, 'fc1_units': 1024, 'fc2_units': 512, 'dropout_rate': 0.4822311384888243, 'lr': 0.001559571523089624, 'batch_size': 32}. Best is trial 3 with value: 96.38499999999999.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 04:13:18,303] Trial 5 finished with value: 96.48333333333332 and parameters: {'conv1_out': 128, 'conv2_out': 256, 'conv3_out': 256, 'fc1_units': 2048, 'fc2_units': 512, 'dropout_rate': 0.4269635020975987, 'lr': 0.001972710676299108, 'batch_size': 32}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 04:40:52,415] Trial 6 finished with value: 96.25666666666666 and parameters: {'conv1_out': 256, 'conv2_out': 128, 'conv3_out': 256, 'fc1_units': 1024, 'fc2_units': 512, 'dropout_rate': 0.3001432210786498, 'lr': 0.00022867723257136044, 'batch_size': 32}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 05:13:16,637] Trial 7 finished with value: 96.46 and parameters: {'conv1_out': 128, 'conv2_out': 512, 'conv3_out': 512, 'fc1_units': 1024, 'fc2_units': 1024, 'dropout_rate': 0.3374457871040153, 'lr': 0.0008436088152363866, 'batch_size': 32}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 05:32:05,920] Trial 8 finished with value: 94.16 and parameters: {'conv1_out': 64, 'conv2_out': 256, 'conv3_out': 1024, 'fc1_units': 2048, 'fc2_units': 1024, 'dropout_rate': 0.32962130135792683, 'lr': 0.0005277841936620773, 'batch_size': 64}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 05:39:35,456] Trial 9 finished with value: 92.425 and parameters: {'conv1_out': 128, 'conv2_out': 256, 'conv3_out': 256, 'fc1_units': 2048, 'fc2_units': 512, 'dropout_rate': 0.325510311296751, 'lr': 7.825030586774794e-05, 'batch_size': 128}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 05:48:00,992] Trial 10 finished with value: 94.535 and parameters: {'conv1_out': 128, 'conv2_out': 512, 'conv3_out': 256, 'fc1_units': 2048, 'fc2_units': 1024, 'dropout_rate': 0.49471046510239103, 'lr': 0.00860198800372409, 'batch_size': 128}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 06:21:36,465] Trial 11 finished with value: 45.3 and parameters: {'conv1_out': 128, 'conv2_out': 512, 'conv3_out': 512, 'fc1_units': 2048, 'fc2_units': 1024, 'dropout_rate': 0.26001396374336583, 'lr': 0.005637478692514793, 'batch_size': 32}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 06:51:26,708] Trial 12 finished with value: 94.37833333333333 and parameters: {'conv1_out': 128, 'conv2_out': 512, 'conv3_out': 256, 'fc1_units': 1024, 'fc2_units': 1024, 'dropout_rate': 0.3733056091432337, 'lr': 1.3249573291289627e-05, 'batch_size': 32}. Best is trial 5 with value: 96.48333333333332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n",
      "Using 4 GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "# Define the ExtendedCNN with tunable hyperparameters\n",
    "class ExtendedCNN(nn.Module):\n",
    "    def __init__(self, conv1_out=128, conv2_out=256, conv3_out=512, fc1_units=2048, fc2_units=1024, dropout_rate=0.5):\n",
    "        super(ExtendedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(conv2_out)\n",
    "        self.conv3 = nn.Conv2d(conv2_out, conv3_out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(conv3_out)\n",
    "        self.conv4 = nn.Conv2d(conv3_out, 1024, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(1024)\n",
    "        self.conv5 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(1024, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 512)\n",
    "        self.fc4 = nn.Linear(512, 10)  # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # Downsample\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))            # No pooling\n",
    "        x = torch.relu(self.bn5(self.conv5(x)))            # No pooling\n",
    "        x = self.global_pool(x)                            # Global average pooling\n",
    "        x = x.view(x.size(0), -1)                          # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    conv1_out = trial.suggest_categorical('conv1_out', [64, 128, 256])\n",
    "    conv2_out = trial.suggest_categorical('conv2_out', [128, 256, 512])\n",
    "    conv3_out = trial.suggest_categorical('conv3_out', [256, 512, 1024])\n",
    "    fc1_units = trial.suggest_categorical('fc1_units', [1024, 2048])\n",
    "    fc2_units = trial.suggest_categorical('fc2_units', [512, 1024])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = ExtendedCNN(\n",
    "            conv1_out=conv1_out,\n",
    "            conv2_out=conv2_out,\n",
    "            conv3_out=conv3_out,\n",
    "            fc1_units=fc1_units,\n",
    "            fc2_units=fc2_units,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Wrap model with DataParallel to use multiple GPUs\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"Using {device_count} GPUs\")\n",
    "        model = nn.DataParallel(model).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(10):  # 10 epochs per trial\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Return mean validation accuracy\n",
    "    return sum(val_accuracies) / len(val_accuracies)\n",
    "\n",
    "\n",
    "# Dataset (Replace `CustomDataset` with your actual dataset)\n",
    "dataset = CustomDataset(train_data, train_labels)\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best trial\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 16:13:16,495] A new study created in memory with name: no-name-ff40f827-79b3-4335-8cf7-00bd4835ad4c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 16:20:37,037] A new study created in memory with name: no-name-f9d2e0ad-4dda-432a-9e5b-c69916af8bc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 4 GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-12-06 16:25:20,219] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 122\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Run the Optuna study\u001b[39;00m\n\u001b[1;32m    121\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 122\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Output the best trial\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest trial:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[9], line 93\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     91\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     92\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 93\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     95\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:171\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:181\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:81\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     79\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m---> 81\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     83\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/threading.py:1011\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1011\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1013\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.8/threading.py:1027\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lock \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# already determined that the C code is done\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_stopped\n\u001b[0;32m-> 1027\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1028\u001b[0m     lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "\n",
    "# Define the ExtendedCNN with tunable hyperparameters\n",
    "class ExtendedCNN(nn.Module):\n",
    "    def __init__(self, conv1_out=128, conv2_out=256, conv3_out=512, fc1_units=2048, fc2_units=1024, dropout_rate=0.5):\n",
    "        super(ExtendedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(conv2_out)\n",
    "        self.conv3 = nn.Conv2d(conv2_out, conv3_out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(conv3_out)\n",
    "        self.conv4 = nn.Conv2d(conv3_out, 1024, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(1024)\n",
    "        self.conv5 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(1024, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 512)\n",
    "        self.fc4 = nn.Linear(512, 10)  # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # Downsample\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))            # No pooling\n",
    "        x = torch.relu(self.bn5(self.conv5(x)))            # No pooling\n",
    "        x = self.global_pool(x)                            # Global average pooling\n",
    "        x = x.view(x.size(0), -1)                          # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Define the search space\n",
    "    conv1_out = trial.suggest_categorical('conv1_out', [64, 128, 256])\n",
    "    conv2_out = trial.suggest_categorical('conv2_out', [128, 256, 512])\n",
    "    conv3_out = trial.suggest_categorical('conv3_out', [256, 512, 1024])\n",
    "    fc1_units = trial.suggest_categorical('fc1_units', [1024, 2048])\n",
    "    fc2_units = trial.suggest_categorical('fc2_units', [512, 1024])\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.2, 0.5)\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "    \n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    val_accuracies = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model\n",
    "        model = ExtendedCNN(\n",
    "            conv1_out=conv1_out,\n",
    "            conv2_out=conv2_out,\n",
    "            conv3_out=conv3_out,\n",
    "            fc1_units=fc1_units,\n",
    "            fc2_units=fc2_units,\n",
    "            dropout_rate=dropout_rate\n",
    "        )\n",
    "        \n",
    "        # Wrap model with DataParallel to use multiple GPUs\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        device_count = torch.cuda.device_count()\n",
    "        print(f\"Using {device_count} GPUs\")\n",
    "        model = nn.DataParallel(model).to(device)\n",
    "\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(10):  # 10 epochs per trial\n",
    "            model.train()\n",
    "            for images, labels in train_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = 100 * correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "    # Return mean validation accuracy\n",
    "    return sum(val_accuracies) / len(val_accuracies)\n",
    "\n",
    "\n",
    "# Dataset (Replace `CustomDataset` with your actual dataset)\n",
    "dataset = CustomDataset(train_data, train_labels)\n",
    "\n",
    "# Run the Optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Output the best trial\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"  Value: {trial.value}\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch 1, Validation Accuracy: 74.42%\n",
      "Epoch 2, Validation Accuracy: 92.90%\n",
      "Epoch 3, Validation Accuracy: 94.92%\n",
      "Epoch 4, Validation Accuracy: 95.47%\n",
      "Epoch 5, Validation Accuracy: 96.42%\n",
      "Epoch 6, Validation Accuracy: 95.96%\n",
      "Epoch 7, Validation Accuracy: 95.88%\n",
      "Epoch 8, Validation Accuracy: 96.76%\n",
      "Epoch 9, Validation Accuracy: 96.18%\n",
      "Epoch 10, Validation Accuracy: 96.58%\n",
      "Fold 2\n",
      "Epoch 1, Validation Accuracy: 11.25%\n",
      "Epoch 2, Validation Accuracy: 11.25%\n",
      "Epoch 3, Validation Accuracy: 11.25%\n",
      "Epoch 4, Validation Accuracy: 11.25%\n",
      "Epoch 5, Validation Accuracy: 11.25%\n",
      "Epoch 6, Validation Accuracy: 11.25%\n",
      "Epoch 7, Validation Accuracy: 11.25%\n",
      "Epoch 8, Validation Accuracy: 11.25%\n",
      "Epoch 9, Validation Accuracy: 11.25%\n",
      "Epoch 10, Validation Accuracy: 11.25%\n",
      "Fold 3\n",
      "Epoch 1, Validation Accuracy: 77.03%\n",
      "Epoch 2, Validation Accuracy: 94.08%\n",
      "Epoch 3, Validation Accuracy: 94.96%\n",
      "Epoch 4, Validation Accuracy: 95.70%\n",
      "Epoch 5, Validation Accuracy: 95.43%\n",
      "Epoch 6, Validation Accuracy: 96.53%\n",
      "Epoch 7, Validation Accuracy: 96.62%\n",
      "Epoch 8, Validation Accuracy: 96.38%\n",
      "Epoch 9, Validation Accuracy: 97.00%\n",
      "Epoch 10, Validation Accuracy: 96.24%\n",
      "Fold 4\n",
      "Epoch 1, Validation Accuracy: 74.92%\n",
      "Epoch 2, Validation Accuracy: 93.03%\n",
      "Epoch 3, Validation Accuracy: 93.88%\n",
      "Epoch 4, Validation Accuracy: 95.60%\n",
      "Epoch 5, Validation Accuracy: 96.12%\n",
      "Epoch 6, Validation Accuracy: 95.93%\n",
      "Epoch 7, Validation Accuracy: 96.58%\n",
      "Epoch 8, Validation Accuracy: 95.92%\n",
      "Epoch 9, Validation Accuracy: 94.84%\n",
      "Epoch 10, Validation Accuracy: 96.80%\n",
      "Fold 5\n",
      "Epoch 1, Validation Accuracy: 11.56%\n",
      "Epoch 2, Validation Accuracy: 11.56%\n",
      "Epoch 3, Validation Accuracy: 11.56%\n",
      "Epoch 4, Validation Accuracy: 11.56%\n",
      "Epoch 5, Validation Accuracy: 11.56%\n",
      "Epoch 6, Validation Accuracy: 11.56%\n",
      "Epoch 7, Validation Accuracy: 11.56%\n",
      "Epoch 8, Validation Accuracy: 11.56%\n",
      "Epoch 9, Validation Accuracy: 11.56%\n",
      "Epoch 10, Validation Accuracy: 11.56%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Define the best hyperparameters from Optuna\n",
    "BEST_PARAMS = {\n",
    "    'conv1_out': 256,\n",
    "    'conv2_out': 256,\n",
    "    'conv3_out': 512,\n",
    "    'fc1_units': 1024,\n",
    "    'fc2_units': 512,\n",
    "    'dropout_rate': 0.21236856575906027,\n",
    "    'lr': 0.0032347111827300164,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Updated SimpleCNN model with the best parameters\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, conv1_out=256, conv2_out=256, conv3_out=512, fc1_units=1024, fc2_units=512, dropout_rate=0.21236856575906027):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5, padding=2)\n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv2d(conv2_out, conv3_out, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(conv3_out * 3 * 3, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 10)  # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # First convolution + pooling\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # Second convolution + pooling\n",
    "        x = self.pool(torch.relu(self.conv3(x)))  # Third convolution + pooling\n",
    "        x = x.view(-1, x.size(1) * x.size(2) * x.size(3))  # Flatten\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))  # Fully connected + dropout\n",
    "        x = torch.relu(self.fc2(x))  # Second fully connected layer\n",
    "        x = self.fc3(x)  # Final layer\n",
    "        return x\n",
    "\n",
    "class ExtendedCNN(nn.Module):\n",
    "    def __init__(self, conv1_out=256, conv2_out=256, conv3_out=512, fc1_units=1024, fc2_units=512, dropout_rate=0.21236856575906027):\n",
    "        super(ExtendedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(conv2_out)\n",
    "        self.conv3 = nn.Conv2d(conv2_out, conv3_out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(conv3_out)\n",
    "        self.conv4 = nn.Conv2d(conv3_out, 1024, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(1024)\n",
    "        self.conv5 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(1024)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(1024, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 512)\n",
    "        self.fc4 = nn.Linear(512, 10)  # 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))  # Downsample\n",
    "        x = self.pool(torch.relu(self.bn3(self.conv3(x))))  # Downsample\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))            # No pooling\n",
    "        x = torch.relu(self.bn5(self.conv5(x)))            # No pooling\n",
    "        x = self.global_pool(x)                            # Global average pooling\n",
    "        x = x.view(x.size(0), -1)                          # Flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Dataset (Replace with your dataset)\n",
    "dataset = CustomDataset(train_data, train_labels)\n",
    "\n",
    "# 5-fold Cross-Validation\n",
    "kkf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Cross-Validation Loop\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_data, train_labels)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    \n",
    "    # Create Subsets\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Initialize the model with best parameters\n",
    "    model = ExtendedCNN().to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=BEST_PARAMS['lr'])\n",
    "\n",
    "    # Training and validation loop\n",
    "    for epoch in range(10):  # Adjust the number of epochs as needed\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}, Validation Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: Counter({tensor(1): 1, tensor(6): 1, tensor(7): 1, tensor(1): 1, tensor(7): 1, tensor(0): 1, tensor(2): 1, tensor(6): 1, tensor(6): 1, tensor(3): 1, tensor(9): 1, tensor(3): 1, tensor(8): 1, tensor(6): 1, tensor(7): 1, tensor(5): 1, tensor(6): 1, tensor(1): 1, tensor(6): 1, tensor(2): 1, tensor(1): 1, tensor(2): 1, tensor(8): 1, tensor(0): 1, tensor(9): 1, tensor(6): 1, tensor(7): 1, tensor(8): 1, tensor(2): 1, tensor(5): 1, tensor(4): 1, tensor(0): 1, tensor(3): 1, tensor(8): 1, tensor(3): 1, tensor(7): 1, tensor(7): 1, tensor(7): 1, tensor(6): 1, tensor(6): 1, tensor(8): 1, tensor(0): 1, tensor(6): 1, tensor(2): 1, tensor(1): 1, tensor(7): 1, tensor(8): 1, tensor(5): 1, tensor(0): 1, tensor(9): 1, tensor(0): 1, tensor(9): 1, tensor(3): 1, tensor(1): 1, tensor(0): 1, tensor(4): 1, tensor(6): 1, tensor(6): 1, tensor(6): 1, tensor(1): 1, tensor(3): 1, tensor(4): 1, tensor(0): 1, tensor(9): 1, tensor(3): 1, tensor(4): 1, tensor(5): 1, tensor(1): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(2): 1, tensor(5): 1, tensor(5): 1, tensor(7): 1, tensor(5): 1, tensor(0): 1, tensor(5): 1, tensor(6): 1, tensor(0): 1, tensor(9): 1, tensor(7): 1, tensor(1): 1, tensor(2): 1, tensor(6): 1, tensor(4): 1, tensor(0): 1, tensor(7): 1, tensor(1): 1, tensor(2): 1, tensor(5): 1, tensor(4): 1, tensor(5): 1, tensor(3): 1, tensor(4): 1, tensor(1): 1, tensor(7): 1, tensor(5): 1, tensor(2): 1, tensor(1): 1, tensor(4): 1, tensor(3): 1, tensor(7): 1, tensor(3): 1, tensor(6): 1, tensor(5): 1, tensor(1): 1, tensor(4): 1, tensor(6): 1, tensor(6): 1, tensor(3): 1, tensor(8): 1, tensor(9): 1, tensor(2): 1, tensor(9): 1, tensor(4): 1, tensor(9): 1, tensor(9): 1, tensor(6): 1, tensor(9): 1, tensor(1): 1, tensor(3): 1, tensor(5): 1, tensor(3): 1, tensor(1): 1, tensor(6): 1, tensor(7): 1, tensor(4): 1, tensor(3): 1, tensor(0): 1, tensor(2): 1, tensor(9): 1, tensor(7): 1, tensor(0): 1, tensor(4): 1, tensor(1): 1, tensor(8): 1, tensor(2): 1, tensor(2): 1, tensor(2): 1, tensor(4): 1, tensor(6): 1, tensor(8): 1, tensor(1): 1, tensor(1): 1, tensor(8): 1, tensor(8): 1, tensor(1): 1, tensor(4): 1, tensor(7): 1, tensor(8): 1, tensor(3): 1, tensor(4): 1, tensor(7): 1, tensor(6): 1, tensor(0): 1, tensor(7): 1, tensor(7): 1, tensor(0): 1, tensor(1): 1, tensor(5): 1, tensor(9): 1, tensor(2): 1, tensor(9): 1, tensor(0): 1, tensor(7): 1, tensor(8): 1, tensor(1): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(9): 1, tensor(2): 1, tensor(3): 1, tensor(4): 1, tensor(1): 1, tensor(8): 1, tensor(4): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(5): 1, tensor(2): 1, tensor(4): 1, tensor(2): 1, tensor(2): 1, tensor(8): 1, tensor(7): 1, tensor(6): 1, tensor(2): 1, tensor(6): 1, tensor(1): 1, tensor(9): 1, tensor(9): 1, tensor(0): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(5): 1, tensor(8): 1, tensor(8): 1, tensor(3): 1, tensor(4): 1, tensor(0): 1, tensor(4): 1, tensor(6): 1, tensor(6): 1, tensor(1): 1, tensor(4): 1, tensor(7): 1, tensor(9): 1, tensor(8): 1, tensor(2): 1, tensor(1): 1, tensor(6): 1, tensor(0): 1, tensor(2): 1, tensor(4): 1, tensor(7): 1, tensor(5): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(5): 1, tensor(8): 1, tensor(0): 1, tensor(5): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(3): 1, tensor(8): 1, tensor(9): 1, tensor(3): 1, tensor(4): 1, tensor(5): 1, tensor(0): 1, tensor(5): 1, tensor(9): 1, tensor(5): 1, tensor(5): 1, tensor(0): 1, tensor(2): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(8): 1, tensor(8): 1, tensor(5): 1, tensor(0): 1, tensor(5): 1, tensor(8): 1, tensor(8): 1, tensor(5): 1, tensor(8): 1, tensor(1): 1, tensor(0): 1, tensor(3): 1, tensor(5): 1, tensor(0): 1, tensor(8): 1, tensor(6): 1, tensor(5): 1, tensor(8): 1, tensor(7): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(4): 1, tensor(4): 1, tensor(9): 1, tensor(2): 1, tensor(6): 1, tensor(1): 1, tensor(5): 1, tensor(5): 1, tensor(4): 1, tensor(2): 1, tensor(4): 1, tensor(6): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(3): 1, tensor(5): 1, tensor(1): 1, tensor(9): 1, tensor(2): 1, tensor(1): 1, tensor(1): 1, tensor(8): 1, tensor(9): 1, tensor(1): 1, tensor(0): 1, tensor(6): 1, tensor(3): 1, tensor(4): 1, tensor(8): 1, tensor(3): 1, tensor(2): 1, tensor(9): 1, tensor(2): 1, tensor(9): 1, tensor(2): 1, tensor(2): 1, tensor(9): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(7): 1, tensor(2): 1, tensor(9): 1, tensor(4): 1, tensor(1): 1, tensor(9): 1, tensor(9): 1, tensor(5): 1, tensor(1): 1, tensor(1): 1, tensor(2): 1, tensor(7): 1, tensor(6): 1, tensor(2): 1, tensor(2): 1, tensor(9): 1, tensor(0): 1, tensor(7): 1, tensor(7): 1, tensor(4): 1, tensor(6): 1, tensor(4): 1, tensor(8): 1, tensor(3): 1, tensor(8): 1, tensor(9): 1, tensor(1): 1, tensor(0): 1, tensor(9): 1, tensor(8): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(1): 1, tensor(7): 1, tensor(0): 1, tensor(5): 1, tensor(0): 1, tensor(5): 1, tensor(2): 1, tensor(8): 1, tensor(6): 1, tensor(6): 1, tensor(7): 1, tensor(1): 1, tensor(6): 1, tensor(4): 1, tensor(5): 1, tensor(1): 1, tensor(6): 1, tensor(0): 1, tensor(0): 1, tensor(1): 1, tensor(8): 1, tensor(8): 1, tensor(6): 1, tensor(1): 1, tensor(1): 1, tensor(7): 1, tensor(7): 1, tensor(9): 1, tensor(7): 1, tensor(5): 1, tensor(8): 1, tensor(6): 1, tensor(8): 1, tensor(7): 1, tensor(8): 1, tensor(8): 1, tensor(0): 1, tensor(0): 1, tensor(0): 1, tensor(7): 1, tensor(7): 1, tensor(0): 1, tensor(9): 1, tensor(5): 1, tensor(3): 1, tensor(9): 1, tensor(3): 1, tensor(2): 1, tensor(6): 1, tensor(4): 1, tensor(4): 1, tensor(5): 1, tensor(0): 1, tensor(4): 1, tensor(5): 1, tensor(9): 1, tensor(5): 1, tensor(8): 1, tensor(3): 1, tensor(9): 1, tensor(6): 1, tensor(1): 1, tensor(6): 1, tensor(4): 1, tensor(2): 1, tensor(5): 1, tensor(6): 1, tensor(8): 1, tensor(0): 1, tensor(9): 1, tensor(7): 1, tensor(5): 1, tensor(4): 1, tensor(6): 1, tensor(2): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(1): 1, tensor(1): 1, tensor(3): 1, tensor(9): 1, tensor(2): 1, tensor(7): 1, tensor(7): 1, tensor(3): 1, tensor(9): 1, tensor(7): 1, tensor(0): 1, tensor(8): 1, tensor(2): 1, tensor(9): 1, tensor(3): 1, tensor(5): 1, tensor(5): 1, tensor(0): 1, tensor(6): 1, tensor(5): 1, tensor(0): 1, tensor(7): 1, tensor(6): 1, tensor(7): 1, tensor(4): 1, tensor(3): 1, tensor(6): 1, tensor(1): 1, tensor(1): 1, tensor(6): 1, tensor(0): 1, tensor(4): 1, tensor(1): 1, tensor(0): 1, tensor(9): 1, tensor(8): 1, tensor(6): 1, tensor(3): 1, tensor(8): 1, tensor(3): 1, tensor(5): 1, tensor(8): 1, tensor(9): 1, tensor(4): 1, tensor(4): 1, tensor(9): 1, tensor(3): 1, tensor(7): 1, tensor(7): 1, tensor(9): 1, tensor(3): 1, tensor(2): 1, tensor(8): 1, tensor(0): 1, tensor(2): 1, tensor(9): 1, tensor(8): 1, tensor(2): 1, tensor(6): 1, tensor(0): 1, tensor(9): 1, tensor(3): 1, tensor(6): 1, tensor(3): 1, tensor(9): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(1): 1, tensor(7): 1, tensor(1): 1, tensor(0): 1, tensor(8): 1, tensor(3): 1, tensor(8): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(4): 1, tensor(9): 1, tensor(5): 1, tensor(4): 1, tensor(5): 1, tensor(3): 1, tensor(7): 1, tensor(2): 1, tensor(8): 1, tensor(3): 1, tensor(9): 1, tensor(5): 1, tensor(8): 1, tensor(7): 1, tensor(1): 1, tensor(7): 1, tensor(9): 1, tensor(8): 1, tensor(2): 1, tensor(9): 1, tensor(9): 1, tensor(7): 1, tensor(4): 1, tensor(2): 1, tensor(9): 1, tensor(8): 1, tensor(7): 1, tensor(2): 1, tensor(2): 1, tensor(8): 1, tensor(1): 1, tensor(2): 1, tensor(2): 1, tensor(5): 1, tensor(6): 1, tensor(5): 1, tensor(3): 1, tensor(5): 1, tensor(6): 1, tensor(8): 1, tensor(4): 1, tensor(9): 1, tensor(9): 1, tensor(7): 1, tensor(2): 1, tensor(9): 1, tensor(0): 1, tensor(2): 1, tensor(6): 1, tensor(0): 1, tensor(9): 1, tensor(1): 1, tensor(0): 1, tensor(5): 1, tensor(7): 1, tensor(1): 1, tensor(7): 1, tensor(2): 1, tensor(8): 1, tensor(7): 1, tensor(7): 1, tensor(8): 1, tensor(3): 1, tensor(4): 1, tensor(4): 1, tensor(8): 1, tensor(7): 1, tensor(4): 1, tensor(5): 1, tensor(2): 1, tensor(0): 1, tensor(5): 1, tensor(8): 1, tensor(8): 1, tensor(7): 1, tensor(6): 1, tensor(0): 1, tensor(6): 1, tensor(2): 1, tensor(8): 1, tensor(9): 1, tensor(6): 1, tensor(3): 1, tensor(5): 1, tensor(5): 1, tensor(5): 1, tensor(3): 1, tensor(2): 1, tensor(0): 1, tensor(9): 1, tensor(6): 1, tensor(9): 1, tensor(0): 1, tensor(3): 1, tensor(6): 1, tensor(9): 1, tensor(9): 1, tensor(4): 1, tensor(8): 1, tensor(2): 1, tensor(0): 1, tensor(3): 1, tensor(4): 1, tensor(5): 1, tensor(3): 1, tensor(8): 1, tensor(8): 1, tensor(5): 1, tensor(7): 1, tensor(0): 1, tensor(0): 1, tensor(8): 1, tensor(7): 1, tensor(7): 1, tensor(0): 1, tensor(0): 1, tensor(4): 1, tensor(7): 1, tensor(8): 1, tensor(7): 1, tensor(0): 1, tensor(9): 1, tensor(0): 1, tensor(3): 1, tensor(4): 1, tensor(0): 1, tensor(5): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(9): 1, tensor(2): 1, tensor(3): 1, tensor(4): 1, tensor(4): 1, tensor(0): 1, tensor(8): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(8): 1, tensor(8): 1, tensor(1): 1, tensor(7): 1, tensor(6): 1, tensor(0): 1, tensor(9): 1, tensor(0): 1, tensor(5): 1, tensor(5): 1, tensor(4): 1, tensor(0): 1, tensor(5): 1, tensor(7): 1, tensor(2): 1, tensor(4): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(3): 1, tensor(4): 1, tensor(5): 1, tensor(4): 1, tensor(0): 1, tensor(9): 1, tensor(1): 1, tensor(3): 1, tensor(9): 1, tensor(7): 1, tensor(2): 1, tensor(7): 1, tensor(1): 1, tensor(6): 1, tensor(1): 1, tensor(8): 1, tensor(9): 1, tensor(2): 1, tensor(2): 1, tensor(0): 1, tensor(0): 1, tensor(3): 1, tensor(6): 1, tensor(1): 1, tensor(1): 1, tensor(9): 1, tensor(7): 1, tensor(5): 1, tensor(3): 1, tensor(2): 1, tensor(2): 1, tensor(9): 1, tensor(3): 1, tensor(0): 1, tensor(9): 1, tensor(4): 1, tensor(1): 1, tensor(8): 1, tensor(1): 1, tensor(0): 1, tensor(9): 1, tensor(3): 1, tensor(0): 1, tensor(3): 1, tensor(1): 1, tensor(8): 1, tensor(6): 1, tensor(9): 1, tensor(7): 1, tensor(3): 1, tensor(3): 1, tensor(6): 1, tensor(3): 1, tensor(0): 1, tensor(8): 1, tensor(4): 1, tensor(8): 1, tensor(9): 1, tensor(5): 1, tensor(0): 1, tensor(0): 1, tensor(5): 1, tensor(5): 1, tensor(2): 1, tensor(9): 1, tensor(1): 1, tensor(5): 1, tensor(9): 1, tensor(0): 1, tensor(4): 1, tensor(1): 1, tensor(8): 1, tensor(8): 1, tensor(1): 1, tensor(9): 1, tensor(8): 1, tensor(8): 1, tensor(8): 1, tensor(1): 1, tensor(4): 1, tensor(0): 1, tensor(8): 1, tensor(8): 1, tensor(6): 1, tensor(2): 1, tensor(9): 1, tensor(0): 1, tensor(4): 1, tensor(3): 1, tensor(0): 1, tensor(7): 1, tensor(9): 1, tensor(6): 1, tensor(7): 1, tensor(7): 1, tensor(8): 1, tensor(4): 1, tensor(3): 1, tensor(0): 1, tensor(3): 1, tensor(6): 1, tensor(9): 1, tensor(3): 1, tensor(4): 1, tensor(9): 1, tensor(1): 1, tensor(3): 1, tensor(7): 1, tensor(0): 1, tensor(6): 1, tensor(0): 1, tensor(2): 1, tensor(8): 1, tensor(9): 1, tensor(4): 1, tensor(0): 1, tensor(2): 1, tensor(1): 1, tensor(7): 1, tensor(5): 1, tensor(3): 1, tensor(5): 1, tensor(6): 1, tensor(0): 1, tensor(0): 1, tensor(6): 1, tensor(3): 1, tensor(5): 1, tensor(3): 1, tensor(6): 1, tensor(1): 1, tensor(2): 1, tensor(6): 1, tensor(1): 1, tensor(3): 1, tensor(8): 1, tensor(1): 1, tensor(4): 1, tensor(7): 1, tensor(0): 1, tensor(8): 1, tensor(3): 1, tensor(0): 1, tensor(3): 1, tensor(2): 1, tensor(8): 1, tensor(4): 1, tensor(5): 1, tensor(7): 1, tensor(6): 1, tensor(8): 1, tensor(3): 1, tensor(4): 1, tensor(4): 1, tensor(7): 1, tensor(2): 1, tensor(7): 1, tensor(6): 1, tensor(3): 1, tensor(3): 1, tensor(1): 1, tensor(1): 1, tensor(3): 1, tensor(7): 1, tensor(4): 1, tensor(8): 1, tensor(9): 1, tensor(9): 1, tensor(8): 1, tensor(1): 1, tensor(9): 1, tensor(4): 1, tensor(2): 1, tensor(6): 1, tensor(3): 1, tensor(2): 1, tensor(9): 1, tensor(8): 1, tensor(3): 1, tensor(6): 1, tensor(8): 1, tensor(7): 1, tensor(7): 1, tensor(2): 1, tensor(2): 1, tensor(4): 1, tensor(9): 1, tensor(5): 1, tensor(1): 1, tensor(8): 1, tensor(1): 1, tensor(3): 1, tensor(9): 1, tensor(9): 1, tensor(5): 1, tensor(6): 1, tensor(5): 1, tensor(2): 1, tensor(6): 1, tensor(2): 1, tensor(5): 1, tensor(0): 1, tensor(4): 1, tensor(5): 1, tensor(5): 1, tensor(2): 1, tensor(0): 1, tensor(2): 1, tensor(8): 1, tensor(5): 1, tensor(4): 1, tensor(2): 1, tensor(4): 1, tensor(4): 1, tensor(1): 1, tensor(3): 1, tensor(9): 1, tensor(2): 1, tensor(0): 1, tensor(4): 1, tensor(6): 1, tensor(1): 1, tensor(8): 1, tensor(0): 1, tensor(2): 1, tensor(8): 1, tensor(6): 1, tensor(6): 1, tensor(8): 1, tensor(5): 1, tensor(9): 1, tensor(2): 1, tensor(3): 1, tensor(9): 1, tensor(1): 1, tensor(9): 1, tensor(7): 1, tensor(8): 1, tensor(0): 1, tensor(2): 1, tensor(6): 1, tensor(2): 1, tensor(2): 1, tensor(4): 1, tensor(9): 1, tensor(0): 1, tensor(7): 1, tensor(5): 1, tensor(0): 1, tensor(7): 1, tensor(8): 1, tensor(4): 1, tensor(0): 1, tensor(8): 1, tensor(5): 1, tensor(0): 1, tensor(7): 1, tensor(5): 1, tensor(0): 1, tensor(9): 1, tensor(7): 1, tensor(2): 1, tensor(0): 1, tensor(6): 1, tensor(9): 1, tensor(7): 1, tensor(6): 1, tensor(5): 1, tensor(2): 1, tensor(2): 1, tensor(7): 1, tensor(0): 1, tensor(4): 1, tensor(5): 1, tensor(4): 1, tensor(2): 1, tensor(7): 1, tensor(2): 1, tensor(3): 1, tensor(7): 1, tensor(1): 1, tensor(0): 1, tensor(1): 1, tensor(1): 1, tensor(0): 1, tensor(8): 1, tensor(9): 1, tensor(8): 1, tensor(2): 1, tensor(4): 1, tensor(3): 1, tensor(6): 1, tensor(5): 1, tensor(8): 1, tensor(4): 1, tensor(3): 1, tensor(1): 1, tensor(4): 1, tensor(6): 1, tensor(9): 1, tensor(6): 1, tensor(9): 1, tensor(2): 1, tensor(3): 1, tensor(0): 1, tensor(7): 1, tensor(1): 1, tensor(5): 1, tensor(2): 1, tensor(5): 1, tensor(1): 1, tensor(0): 1, tensor(3): 1, tensor(3): 1, tensor(7): 1, tensor(2): 1, tensor(4): 1, tensor(4): 1, tensor(5): 1, tensor(0): 1, tensor(1): 1, tensor(2): 1, tensor(5): 1, tensor(0): 1, tensor(1): 1, tensor(4): 1, tensor(0): 1, tensor(9): 1, tensor(5): 1, tensor(9): 1, tensor(4): 1, tensor(3): 1, tensor(7): 1, tensor(6): 1, tensor(5): 1, tensor(3): 1, tensor(0): 1, tensor(9): 1, tensor(6): 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_fold' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_fold' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_fold' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_fold' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/home/shiyao/miniconda3/envs/torch/lib/python3.8/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'train_fold' on <module '__main__' (built-in)>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch.multiprocessing as mp\n",
    "from collections import Counter\n",
    "\n",
    "# Hyperparameters\n",
    "BEST_PARAMS = {\n",
    "    'conv1_out': 256,\n",
    "    'conv2_out': 256,\n",
    "    'conv3_out': 512,\n",
    "    'fc1_units': 1024,\n",
    "    'fc2_units': 512,\n",
    "    'dropout_rate': 0.21236856575906027,\n",
    "    'lr': 0.0032347111827300164,\n",
    "    'batch_size': 32\n",
    "}\n",
    "\n",
    "# Dummy CustomDataset for Example (Replace with actual dataset)\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "# Replace with your actual dataset and labels\n",
    "train_data = torch.randn(1000, 1, 28, 28)  # Example data\n",
    "train_labels = torch.randint(0, 10, (1000,))  # Example labels\n",
    "dataset = CustomDataset(train_data, train_labels)\n",
    "\n",
    "# Verify label distribution\n",
    "train_labels_list = [label for _, label in dataset]\n",
    "print(\"Label distribution:\", Counter(train_labels_list))\n",
    "\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "# Model Definition\n",
    "class ExtendedCNN(nn.Module):\n",
    "    def __init__(self, conv1_out=256, conv2_out=256, conv3_out=512, fc1_units=1024, fc2_units=512, dropout_rate=0.21236856575906027):\n",
    "        super(ExtendedCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, conv1_out, kernel_size=5, padding=2)\n",
    "        self.bn1 = nn.BatchNorm2d(conv1_out)\n",
    "        self.conv2 = nn.Conv2d(conv1_out, conv2_out, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(conv2_out)\n",
    "        self.conv3 = nn.Conv2d(conv2_out, conv3_out, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(conv3_out)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc1 = nn.Linear(conv3_out, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(torch.relu(self.bn2(self.conv2(x))))\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train_fold(fold, train_idx, val_idx, device, dataset):\n",
    "    print(f\"Starting Fold {fold + 1} on GPU {device}\")\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "    train_loader = DataLoader(train_subset, batch_size=BEST_PARAMS['batch_size'], shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=BEST_PARAMS['batch_size'], shuffle=False)\n",
    "\n",
    "    model = ExtendedCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=BEST_PARAMS['lr'])\n",
    "\n",
    "    for epoch in range(10):  # Adjust epochs as needed\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f\"Fold {fold + 1}, Epoch {epoch + 1}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    processes = []\n",
    "    devices = [f'cuda:{i}' for i in range(torch.cuda.device_count())]\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_data, train_labels_list)):\n",
    "        device = devices[fold % len(devices)]\n",
    "        p = mp.Process(target=train_fold, args=(fold, train_idx, val_idx, device, dataset))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mp.set_start_method('spawn')  # Required for multiprocessing\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRkVT3g1qlC9"
   },
   "source": [
    "### Run Prediction on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jhK17TdcqlC9",
    "outputId": "c31f1ec9-c476-4529-8bb9-4df26be87adf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions results have been saved to: /home/shiyao/ECSE551-mini-project3/Submission.csv\n"
     ]
    }
   ],
   "source": [
    "# 加载测试数据\n",
    "with open(TEST_PKL_FILE, 'rb') as file:\n",
    "    test_data = pickle.load(file)\n",
    "\n",
    "test_dataset = torch.tensor(test_data, dtype=torch.float32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = ExtendedCNN().to(DEVICE)\n",
    "# 在测试集上进行推理\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for images in test_loader:\n",
    "        images = images.to(DEVICE)  # 移动测试数据到设备上\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# 保存预测结果到 CSV 文件\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': np.arange(1, len(predictions) + 1),\n",
    "    'class': predictions\n",
    "})\n",
    "submission_df.to_csv(SUBMISSION_FILE, index=False)\n",
    "print(f\"Predictions results have been saved to: {SUBMISSION_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
